{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d7c676-4b78-4d5d-8802-6bad7dc7e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d79fb-64a9-4688-a3cb-7dca2c26f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"/content/drive/My Drive/Colab Notebooks/CoE202/Collaborative Filtering\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcff133-832d-4654-8a37-7fe6877c2d29",
   "metadata": {},
   "source": [
    "## Collaborative Filtering (CF)\n",
    "\n",
    "<figure class=\"image\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=185fQI_jd3DewJRSKO7TEIZH6Sjr15UGc\" width=\"50%\" height=\"50%\" title=\"recommender system\" alt=\"recommender system\"></img>\n",
    "</figure>\n",
    "\n",
    "- The most prominent approach to generate recommendations\n",
    "    - Used by large, commercial e-commerce sites\n",
    "    - Well-understood, various algorithms and variations exist\n",
    "    - Applicable in many domains\n",
    "- Use the **wisdom of the crowd** to recommend items\n",
    "- Basic assumption and idea\n",
    "    - Users give ratings to items (implicitly or explicitly)\n",
    "    - <span style=\"color:red\">**Customers who had similar tastes in the past will have similar tastes in the future**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ce4fa-bc1f-4a22-9546-5217ff88bb2e",
   "metadata": {},
   "source": [
    "### Model-based CF\n",
    "#### Matrix Factorization\n",
    "We can factorize **ratings matrix** into **user matrix** and **item matrix**.\n",
    "\n",
    "<figure class=\"image\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1880BHOvpFW66QjjjnnN-exW_HOyX9EkU\" width=\"50%\" height=\"50%\" title=\"recommender system\" alt=\"recommender system\"></img>\n",
    "</figure>\n",
    "\n",
    "We can model directly leveraging only observed **ratings**, while avoiding overfitting through an adequate regularized model, such as :  \n",
    "$min \\frac{1}{2} \\sum_{(u, i)\\in R}{(r_{ui} -\\mu -b_{u}^{user} -b_{i}^{item} -p_{u}q_{i}^{T})^{2}} + \\lambda(|p_{u}|^{2} + |q_{i}|^{2} + {b_{u}^{user}}^{2} + {b_{i}^{item}}^{2})$  \n",
    "where $p_{u}$ and $q_{i}$ are the latent factor of user $u$ and item $i$, respectively.  \n",
    "$b_{u}$ and $b_{i}$ are the bias term of user $u$ and item $i$, respectively.  \n",
    "$\\mu$ is the mean of the observed ratings matrix.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c71cd-ac06-4e04-85b7-9bf81d5800dd",
   "metadata": {},
   "source": [
    "#### Implicit Feedback\n",
    "Recommender systems rely on many different types of feedbacks.  \n",
    "Netflix collects star ratings for movies and TiVo users indicate tehir preferences for TV shows by hitting thumbs-up/dowm buttons.  \n",
    "However, **explicit feedback is not always available**.\n",
    "Therefore, recommenders can infer user preferences from the more abundant **implicit feedback**,  \n",
    "which indirectly reflect opinion through observing user behavior.\n",
    "\n",
    "Implicit feedback can be collected constantly and do not require additional efforts from user.\n",
    "\n",
    "<figure class=\"image\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1WXWuwp2dJp6kqUEkQibrvRpiRktl4am7\" width=\"50%\" height=\"50%\" title=\"recommender system\" alt=\"recommender system\"></img>\n",
    "</figure>\n",
    "\n",
    "The input data associate users and items through $r_{ui}$ values, which we henceforth call *observations*.  \n",
    "For implicit feedback datasets, those values would indicate observations for user actions.  \n",
    "For example, $r_{ui}$ can indicate the number of items $u$ purchased item $i$ or the time $u$ spent on webpage $i$.\n",
    "\n",
    "Prime characteristics of Implicit Feedback.\n",
    "- No negative feedback\n",
    "- Implicit feedback is inherently noisy\n",
    "- Numerical value of implicit feedback indicates confidence\n",
    "- Evaluation of implicity-feedback recommender requires appropriate measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f58d4f3-5b34-496b-99a8-b56c88e967d0",
   "metadata": {},
   "source": [
    "#### OCCF (One Class Collaborative Filtering)\n",
    "OCCF introduces confidence levels on unobserved interaction.\n",
    "- If user $u$ consumed item $i$ ($r_{ui} > 0$), then we have an indication that $u$ likes $i$.\n",
    "- If user $u$ never consumed item $i$, we belive no preference.\n",
    "- i.e., $p_{ui} = \\begin{cases} 1 & r_{ui} > 0 \\\\ 0 & r_{ui} = 0 \\end{cases}$\n",
    "- However, with **varying confidence levels** (Not all consumptions are the same, Not all non-consumptions are the same)\n",
    "- i.e., $c_{ui} = 1 + \\alpha r_{ui}$\n",
    "\n",
    "So we aim to minimize the following equations\n",
    "$min \\sum_{(u, i)}{c_{ui}(p_{ui} -x_{u}^{T}y_{i})^{2}} + \\lambda(\\sum_{u}{||x_{u}||}^{2} + \\sum_{i}{||y_{i}||}^{2})$ \n",
    "\n",
    "From now on, since $p_{ui}$ contains meaning even when $p_{ui}$ equals zero, we should take care of all possible ($u, i$) pairs, rather than only those corresponding to observed data.  \n",
    "Since there are too many pairs, it is not feasible to apply stochastic gradient descent.  \n",
    "Instead, we solve the problem via **Alternating Least Squares (ALS)** algorithm.\n",
    "\n",
    "<figure class=\"image\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1ihADiG1xa-Xspb661zoBDriWRQI-sdbc\" width=\"80%\" height=\"80%\" title=\"recommender system\" alt=\"recommender system\"></img>\n",
    "</figure>\n",
    "\n",
    "OCCF iteratively update the user and item latent with below equations.  \n",
    "$x_{u} = (Y^{T}C^{u}Y + \\lambda I)^{-1}Y^{T}C^{u}p(u)$  \n",
    "$y_{i} = (X^{T}C^{i}X + \\lambda I)^{-1}X^{T}C^{i}p(i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db2ba4-92e2-4e26-9c49-79bf4309b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import data\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352781e-e9a5-43bd-b2ca-16a4fc51f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCCF():\n",
    "    \n",
    "    def __init__(self, train, test, f, epsilon):\n",
    "        \"\"\"\n",
    "        param train : Rating Matrix for train\n",
    "        param test : Rating Matrix for test\n",
    "        param f : latent feature parameter\n",
    "        \"\"\"\n",
    "        \n",
    "        self.R = train # Implication Matrix for training size (m, n)\n",
    "        self.R_test = test # Implication Matrix for test size (m, n)\n",
    "        self.P = np.array(np.vectorize(lambda x: 0 if x==0 else 1)(train), dtype = np.float64) # Preference Matrix for training\n",
    "        self.P_test = np.array(np.vectorize(lambda x: 0 if x==0 else 1)(test), dtype = np.float64) # Preference Matrix for training\n",
    "        self.n_user_rated = np.sum(self.P, axis = 1)\n",
    "        self.n_item_rated = np.sum(self.P, axis = 0)\n",
    "        self.num_users, self.num_items = train.shape\n",
    "        self.alpha = 40\n",
    "        self.reg = 0.002\n",
    "        self.C = 1 + self.alpha * self.R # Confidence Matrix size (m, n)\n",
    "        self.f = f\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : update matrix latent weight and bias\n",
    "        \"\"\"\n",
    "        # init latent features\n",
    "        self.X = np.random.normal(scale = 1.0/self.f, size=(self.num_users, self.f))\n",
    "        self.Y = np.random.normal(scale = 1.0/self.f, size=(self.num_items, self.f))\n",
    "        \n",
    "        count = 0\n",
    "        cost_diff = 1000000\n",
    "        self.training_process = []\n",
    "        self.cost = [0]\n",
    "        time = 0\n",
    "        # repeat ALS until convergence\n",
    "        while cost_diff > self.epsilon :\n",
    "            \n",
    "            start = timer()\n",
    "            count += 1\n",
    "            self.yTy = self.Y.T.dot(self.Y)\n",
    "            for u in range(self.num_users):\n",
    "                self.optimize_x(u)\n",
    "            \n",
    "            self.xTx = self.X.T.dot(self.X)\n",
    "            for i in range(self.num_items):\n",
    "                self.optimize_y(i)\n",
    "            time += (timer() - start)\n",
    "            \n",
    "            cost = self.cost()\n",
    "            self.cost.append(cost)\n",
    "            if count > 1 :\n",
    "                cost_diff = self.cost[count - 1] - self.cost[count]\n",
    "            start_rank = timer()\n",
    "            rank = self.compute_rank()\n",
    "            print(\"time to compute rank : %.4f\" % ( timer() - start_rank ))\n",
    "            self.training_process.append([count, cost_diff, rank])\n",
    "            print(\"count: %d, cost_difference : %.4f, rank : %.4f, time for a epoch : %.4f\"% (count, cost_diff, rank, time))\n",
    "            time = 0\n",
    "\n",
    "                \n",
    "    def optimize_x(self, u):\n",
    "        \"\"\"\n",
    "        Optimize X given user u\n",
    "        \"\"\"\n",
    "        C_u = np.diag(self.C[u, :]) # create diagonal matrix size (n, n)\n",
    "        \n",
    "        # (f,f) matrix\n",
    "        temp1 = self.yTy + self.Y.T.dot(C_u - np.identity(self.num_items)).dot(self.Y) + self.reg * np.identity(self.f)\n",
    "        # (f,1) matrix\n",
    "        temp2 = self.Y.T.dot(C_u).dot(self.P[u])\n",
    "        \n",
    "        self.X[u, :] = np.linalg.solve(temp1, temp2)\n",
    "        \n",
    "    \n",
    "    def optimize_y(self, i):\n",
    "        \"\"\"\n",
    "        Optimize X given user u\n",
    "        \"\"\"\n",
    "        C_i = np.diag(self.C[:, i]) # create diagonal matrix size (m, m)\n",
    "        \n",
    "        # (f,f) matrix\n",
    "        temp1 = self.xTx + self.X.T.dot(C_i - np.identity(self.num_users)).dot(self.X) + self.reg * np.identity(self.f)\n",
    "        # (f,1) matrix\n",
    "        temp2 = self.X.T.dot(C_i).dot(self.P[:, i])\n",
    "        \n",
    "        self.Y[i, :] = np.linalg.solve(temp1, temp2)\n",
    "        \n",
    "  \n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute Loss function\n",
    "        \"\"\"\n",
    "        loss = np.sum(self.C * np.square(self.P - self.X.dot(self.Y.T))) + self.reg * (np.linalg.norm(self.X) + np.linalg.norm(self.Y))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def compute_rank(self):\n",
    "        \n",
    "        prediction = self.X.dot(self.Y.T)\n",
    "        temp_1 = 0\n",
    "        temp_2 = 0\n",
    "        \n",
    "        for x in range(self.num_users) :\n",
    "            inv_pre = -1 * prediction[x, :]\n",
    "            sort_x = inv_pre.argsort() # index starts with 0\n",
    "            sort_x = sort_x.argsort()\n",
    "            rank_x = sort_x / len(sort_x)\n",
    "            \n",
    "            temp_1 += (self.R_test[x, :] * rank_x).sum()\n",
    "            temp_2 += self.R_test[x, :].sum()\n",
    "        \n",
    "        rank = temp_1 / temp_2\n",
    "            \n",
    "        return rank\n",
    "    \n",
    "    \n",
    "    def print_results(self):\n",
    "        \"\"\"\n",
    "        print fit results\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Final P hat matrix:\")\n",
    "        print(self.X.dot(self.Y.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97298ae1-f99b-4aab-84d7-cf80b8990e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)    \n",
    "np.seterr(all=\"warn\")\n",
    "\n",
    "train = data.train\n",
    "test = data.test\n",
    "\n",
    "factorizer = MatrixFactorization(train, test, f=40, epsilon = 100)\n",
    "factorizer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fab2e8-457e-4630-8086-5c6f6ee4eede",
   "metadata": {},
   "source": [
    "#### BPR : Bayesian Personalized Ranking from Implicit Feedback\n",
    "Basically, collaborative filtering models we learned in class are designed for the item prediction task of **personalized ranking**.  \n",
    "But none of them is directly optimized for ranking.  \n",
    "\n",
    "<figure class=\"image\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1zoqtL1RQZaHLDLn9aCR4nuZ2ITxtHHbg\" width=\"70%\" height=\"70%\" title=\"recommender system\" alt=\"recommender system\"></img>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b5071-1b1a-46be-90bf-296d916e028a",
   "metadata": {},
   "source": [
    "BPR presents a generic optimization criterion *BPR-OPT* for personalized ranking that is maximum posterior estimator derived from a Bayesian analysis of the problem.  \n",
    "\n",
    "$p(\\theta|>_{u}) \\propto p(>_{u}|\\theta)p(\\theta)$  \n",
    "\n",
    "$\\prod_{u \\in U}{p(\\theta|>_{u})} = \\prod_{(u, i, j) \\in U \\times I \\times I}{p(i >_{u} j|\\theta)^{\\delta((u, i, j)\\in D_{s})}{(1 - p(i >_{u} j|\\theta))^{\\delta((u, j, i)\\notin D_{s})}}}$  \n",
    "\n",
    "where $\\delta$ is the indicator function:  \n",
    "\n",
    "$\\delta(b) := \\begin{cases} 1 & \\text{if}~b~\\text{is true} \\\\ 0 & \\text{else} \\end{cases}$\n",
    "\n",
    "The above formula can be simplified to \n",
    "\n",
    "$\\prod_{u \\in U}{p(>_{u}|\\theta)} = \\prod_{(u, i, j) \\in D_{s}}{p(i >_{u} j|\\theta)}$\n",
    "\n",
    "So we formulate the maximum posterior estimator to derive our generic optimization criterion for personalized ranking BPR-OPT:  \n",
    "\n",
    "$\\ln p(\\theta | >_{u})$  \n",
    "\n",
    "$ = \\ln p(>_{u}| \\theta)p(\\theta)$  \n",
    "\n",
    "$ = \\prod_{(u, i, j) \\in D_{s}}{\\sigma(\\hat{x}_{uij})p(\\theta)}$  \n",
    "\n",
    "$ = \\sum_{(u, i, j) \\in D_{s}}{\\ln\\sigma(\\hat{x}_{uij}) + \\ln p(\\theta)}$  \n",
    "\n",
    "$ = \\sum_{(u, i, j) \\in D_{s}}{\\ln\\sigma(\\hat{x}_{uij}) - \\lambda_{\\theta} {\\|\\theta\\|}^{2}}$\n",
    "\n",
    "We optimise the criteria using **bootstrapping** based **stochastic gradient descent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed058e3-9461-4b79-b276-ed925053deae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
